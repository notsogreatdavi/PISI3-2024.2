import streamlit as st
import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import LabelEncoder, StandardScaler
from sklearn.ensemble import (
    RandomForestClassifier,
    AdaBoostClassifier,
    GradientBoostingClassifier,
)
from sklearn.metrics import accuracy_score, confusion_matrix, classification_report
import seaborn as sns
import matplotlib.pyplot as plt

# ---- Configura√ß√£o da P√°gina ----
st.set_page_config(
    page_title="Classifica√ß√£o de Desempenho Escolar", page_icon="üìä", layout="wide"
)
st.title("üìä Classifica√ß√£o de Desempenho Escolar")
st.write("---")

# ---- Carregar o Dataset ----
st.subheader("1. Carregando e Explorando o Dataset")
try:
    df_students = pd.read_parquet("./data/new_unistudents.parquet")
    st.success("Dataset carregado com sucesso!")
    if "Change_Grades" in df_students.columns:
        st.write("**Distribui√ß√£o da vari√°vel alvo (Change_Grades):**")
        distribution = df_students["Change_Grades"].value_counts().sort_index()
        st.bar_chart(distribution)
    else:
        st.warning("A vari√°vel 'Change_Grades' n√£o foi encontrada no dataset!")

except Exception as e:
    st.error(f"Erro ao carregar o dataset: {e}")
    st.stop()

# ---- Pr√©-processamento ----
st.subheader("2. Pr√©-processamento dos Dados")
try:
    X = df_students.drop("Change_Grades", axis=1)
    y = df_students["Change_Grades"]

    # Escalar colunas num√©ricas
    num_cols = X.select_dtypes(include=["float64", "int64"]).columns
    scaler = StandardScaler()
    X[num_cols] = scaler.fit_transform(X[num_cols])

    # Codificar a coluna alvo
    le = LabelEncoder()
    y = le.fit_transform(y)

    # Dividir os dados
    X_train, X_test, y_train, y_test = train_test_split(
        X, y, test_size=0.2, random_state=101
    )

    st.success("Dados pr√©-processados com sucesso!")
    st.write(f"**Tamanho do conjunto de treino:** {X_train.shape[0]} linhas")
    st.write(f"**Tamanho do conjunto de teste:** {X_test.shape[0]} linhas")
except Exception as e:
    st.error(f"Erro no pr√©-processamento: {e}")
    st.stop()

# ---- Sele√ß√£o de Modelos ----
st.subheader("3. Treinando e Avaliando os Modelos")
modelos = {
    "Random Forest": RandomForestClassifier(n_estimators=50, random_state=101),
    "Gradient Boosting": GradientBoostingClassifier(n_estimators=50, random_state=101),
    "AdaBoost": AdaBoostClassifier(n_estimators=50, random_state=101),
}
modelo_selecionado = st.selectbox(
    "Escolha um modelo de classifica√ß√£o:", list(modelos.keys())
)
botao_avaliar = st.button("Treinar e Avaliar Modelo")


# ---- Fun√ß√£o para Treinar e Avaliar ----
def treinar_e_avaliar(modelo, X_train, y_train, X_test, y_test):
    modelo.fit(X_train, y_train)
    y_train_pred = modelo.predict(X_train)
    y_test_pred = modelo.predict(X_test)

    # Acur√°cia
    acuracia_treino = accuracy_score(y_train, y_train_pred)
    acuracia_teste = accuracy_score(y_test, y_test_pred)
    st.write(f"**Acur√°cia (Treino):** {acuracia_treino:.2f}")
    st.write(f"**Acur√°cia (Teste):** {acuracia_teste:.2f}")

    # Matriz de Confus√£o
    st.write("**Matriz de Confus√£o (Teste):**")
    cm_teste = confusion_matrix(y_test, y_test_pred)
    fig_teste, ax_teste = plt.subplots(figsize=(5, 4), dpi=120)
    sns.heatmap(
        cm_teste,
        annot=True,
        fmt="d",
        cmap="Blues",
        xticklabels=le.classes_,
        yticklabels=le.classes_,
        ax=ax_teste,
    )
    ax_teste.set_xlabel("Predito")
    ax_teste.set_ylabel("Real")
    st.pyplot(fig_teste)

    # Relat√≥rio de Classifica√ß√£o
    st.write("**Relat√≥rio de Classifica√ß√£o (Treino):**")
    report_treino = classification_report(
        y_train, y_train_pred, target_names=le.classes_, output_dict=True
    )
    st.dataframe(pd.DataFrame(report_treino).transpose())

    st.write("**Relat√≥rio de Classifica√ß√£o (Teste):**")
    report_teste = classification_report(
        y_test, y_test_pred, target_names=le.classes_, output_dict=True
    )
    st.dataframe(pd.DataFrame(report_teste).transpose())

    # Import√¢ncia das Vari√°veis (para modelos baseados em √°rvores)
    if hasattr(modelo, "feature_importances_"):
        st.write("**Import√¢ncia das Vari√°veis:**")
        importances = modelo.feature_importances_
        importances_df = pd.DataFrame(
            {"Vari√°vel": X.columns, "Import√¢ncia": importances}
        )
        importances_df = importances_df.sort_values(by="Import√¢ncia", ascending=False)

        fig_imp, ax_imp = plt.subplots(figsize=(6, 4), dpi=120)
        sns.barplot(
            x="Import√¢ncia",
            y="Vari√°vel",
            data=importances_df.head(10),
            palette="viridis",
            ax=ax_imp,
        )
        ax_imp.set_title("Top 10 Vari√°veis mais Importantes")
        st.pyplot(fig_imp)

        # Gr√°fico adicional: Distribui√ß√£o da vari√°vel mais importante
        top_var = importances_df.iloc[0]["Vari√°vel"]
        st.write(f"**Distribui√ß√£o da vari√°vel mais importante:** {top_var}")
        fig_dist, ax_dist = plt.subplots(
            figsize=(6, 4), dpi=120
        )  # Tamanho reduzido com DPI ajustado
        sns.histplot(df_students[top_var], kde=True, ax=ax_dist, color="purple")
        ax_dist.set_title(f"Distribui√ß√£o de {top_var}")
        st.pyplot(fig_dist)


# ---- Avaliar Modelo Selecionado ----
if botao_avaliar:
    st.write(f"### Avalia√ß√£o do Modelo: **{modelo_selecionado}**")
    treinar_e_avaliar(modelos[modelo_selecionado], X_train, y_train, X_test, y_test)
    
# Adicionar este c√≥digo no final do arquivo, ap√≥s o bloco de avalia√ß√£o dos modelos

# ---- Exporta√ß√£o do Modelo ----
st.subheader("4. Exporta√ß√£o do Modelo para Predi√ß√£o")
st.write("""
Ap√≥s a an√°lise comparativa dos modelos de classifica√ß√£o, o algoritmo Gradient Boosting 
demonstrou performance superior na previs√£o de altera√ß√µes no desempenho escolar. 

Visando a implementa√ß√£o pr√°tica deste conhecimento, procederemos com a exporta√ß√£o do 
modelo treinado em formato pickle, permitindo sua utiliza√ß√£o eficiente na interface 
de predi√ß√£o para novos casos sem a necessidade de retreinamento.
""")

# Bot√£o para exportar o modelo
import pickle
import os

if st.button("Exportar Modelo Gradient Boosting"):
    try:
        # Treinar o modelo com todos os dados dispon√≠veis para m√°xima precis√£o
        modelo_final = GradientBoostingClassifier(n_estimators=50, random_state=101)
        modelo_final.fit(X, y)  # Usando todo o conjunto de dados
        
        # Criar diret√≥rio para modelos se n√£o existir
        os.makedirs("./models", exist_ok=True)
        
        # Salvar o modelo para uso na p√°gina de predi√ß√£o
        with open("./models/gradient_boosting_model.pkl", "wb") as f:
            pickle.dump(modelo_final, f)
        
        # Salvar tamb√©m o LabelEncoder para interpretar as classes de sa√≠da
        with open("./models/label_encoder.pkl", "wb") as f:
            pickle.dump(le, f)
        
        # Salvar o StandardScaler para normalizar os dados de entrada
        with open("./models/standard_scaler.pkl", "wb") as f:
            pickle.dump(scaler, f)
            
        st.success("‚úÖ Modelo Gradient Boosting exportado com sucesso! O algoritmo est√° pronto para realizar predi√ß√µes em tempo real na p√°gina de previs√£o.")
         
    except Exception as e:
        st.error(f"Erro ao exportar o modelo: {e}")