import os
import pickle
import streamlit as st
import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import LabelEncoder, StandardScaler
from sklearn.ensemble import (
    RandomForestClassifier,
    AdaBoostClassifier,
    GradientBoostingClassifier,
)
from sklearn.metrics import accuracy_score, confusion_matrix, classification_report
import seaborn as sns
import matplotlib.pyplot as plt
import shap
import plotly.express as px

# Configura√ß√£o da P√°gina
st.set_page_config(
    page_title="Classifica√ß√£o de Desempenho Escolar", page_icon="üìä", layout="wide"
)
st.title("üìä Classifica√ß√£o de Desempenho Escolar")
st.write("---")

# Carregar o Dataset
st.subheader("1. Carregando e Explorando o Dataset")
try:
    df_students = pd.read_parquet("./data/new_unistudents.parquet")
    st.success("Dataset carregado com sucesso!")
    if "Change_Grades" in df_students.columns:
        st.write("**Distribui√ß√£o da vari√°vel alvo (Change_Grades):**")
        distribution = df_students["Change_Grades"].value_counts().sort_index()
        st.bar_chart(distribution)
    else:
        st.warning("A vari√°vel 'Change_Grades' n√£o foi encontrada no dataset!")
except Exception as e:
    st.error(f"Erro ao carregar o dataset: {e}")
    st.stop()

# Pr√©-processamento
st.subheader("2. Pr√©-processamento dos Dados")
try:
    X = df_students.drop("Change_Grades", axis=1)
    y = df_students["Change_Grades"]

    num_cols = X.select_dtypes(include=["float64", "int64"]).columns
    scaler = StandardScaler()
    X[num_cols] = scaler.fit_transform(X[num_cols])

    le = LabelEncoder()
    y = le.fit_transform(y)

    X_train, X_test, y_train, y_test = train_test_split(
        X, y, test_size=0.2, random_state=101
    )

    st.success("Dados pr√©-processados com sucesso!")
    st.write(f"**Tamanho do conjunto de treino:** {X_train.shape[0]} linhas")
    st.write(f"**Tamanho do conjunto de teste:** {X_test.shape[0]} linhas")
except Exception as e:
    st.error(f"Erro no pr√©-processamento: {e}")
    st.stop()

# Fun√ß√£o para Gerar o Gr√°fico SHAP


def plot_shap(modelo, X_train, X_test):
    st.write("**Gr√°fico SHAP:**")
    try:
        try:
            explainer = shap.TreeExplainer(modelo)
            shap_values = explainer.shap_values(X_test)
        except Exception as e_tree:
            st.warning(
                "TreeExplainer n√£o suportou esse modelo. Utilizando KernelExplainer..."
            )
            X_sample = shap.sample(X_train, 100, random_state=101)
            explainer = shap.KernelExplainer(modelo.predict, X_sample)
            shap_values = explainer.shap_values(X_test, nsamples=100)
        if isinstance(shap_values, list):
            shap_vals = shap_values[1] if len(
                shap_values) > 1 else shap_values[0]
        else:
            shap_vals = shap_values
        shap.summary_plot(shap_vals, X_test, plot_type="dot", show=False)
        fig = plt.gcf()
        st.pyplot(fig)
        plt.clf()
    except Exception as e:
        st.error(f"Erro ao gerar gr√°fico SHAP: {e}")


# Sele√ß√£o de Modelos
st.subheader("3. Treinando e Avaliando os Modelos")
modelos = {
    "Random Forest": RandomForestClassifier(n_estimators=50, random_state=101),
    "Gradient Boosting": GradientBoostingClassifier(n_estimators=50, random_state=101),
    "AdaBoost": AdaBoostClassifier(n_estimators=50, random_state=101),
}
modelo_selecionado = st.selectbox(
    "Escolha um modelo de classifica√ß√£o:", list(modelos.keys())
)
botao_avaliar = st.button("Treinar e Avaliar Modelo")

# Fun√ß√£o para Treinar e Avaliar


def treinar_e_avaliar(modelo, X_train, y_train, X_test, y_test):
    modelo.fit(X_train, y_train)
    y_train_pred = modelo.predict(X_train)
    y_test_pred = modelo.predict(X_test)

    # Acur√°cia
    acuracia_treino = accuracy_score(y_train, y_train_pred)
    acuracia_teste = accuracy_score(y_test, y_test_pred)
    st.write(f"**Acur√°cia (Treino):** {acuracia_treino:.2f}")
    st.write(f"**Acur√°cia (Teste):** {acuracia_teste:.2f}")

    # Matriz de Confus√£o
    st.write("**Matriz de Confus√£o (Teste):**")
    cm_teste = confusion_matrix(y_test, y_test_pred)
    fig_teste, ax_teste = plt.subplots(figsize=(5, 4), dpi=120)
    sns.heatmap(
        cm_teste,
        annot=True,
        fmt="d",
        cmap="Blues",
        xticklabels=le.classes_,
        yticklabels=le.classes_,
        ax=ax_teste,
    )
    ax_teste.set_xlabel("Predito")
    ax_teste.set_ylabel("Real")
    st.pyplot(fig_teste)

    # Relat√≥rio de Classifica√ß√£o com zero_division para evitar avisos
    st.write("**Relat√≥rio de Classifica√ß√£o (Treino):**")
    report_treino = classification_report(
        y_train, y_train_pred, target_names=le.classes_, output_dict=True, zero_division=0
    )
    st.dataframe(pd.DataFrame(report_treino).transpose())

    st.write("**Relat√≥rio de Classifica√ß√£o (Teste):**")
    report_teste = classification_report(
        y_test, y_test_pred, target_names=le.classes_, output_dict=True, zero_division=0
    )
    st.dataframe(pd.DataFrame(report_teste).transpose())

    # Import√¢ncia das Vari√°veis
    if hasattr(modelo, "feature_importances_"):
        st.write("**Import√¢ncia das Vari√°veis:**")
        importances = modelo.feature_importances_
        importances_df = pd.DataFrame(
            {"Vari√°vel": X.columns, "Import√¢ncia": importances}
        )
        importances_df = importances_df.sort_values(
            by="Import√¢ncia", ascending=False
        )

        fig_imp, ax_imp = plt.subplots(figsize=(6, 4), dpi=120)
        sns.barplot(
            x="Import√¢ncia",
            y="Vari√°vel",
            data=importances_df.head(10),
            palette="viridis",
            ax=ax_imp,
        )
        ax_imp.set_title("Top 10 Vari√°veis mais Importantes")
        st.pyplot(fig_imp)

        # Distribui√ß√£o da vari√°vel mais importante
        top_var = importances_df.iloc[0]["Vari√°vel"]
        st.write(f"**Distribui√ß√£o da vari√°vel mais importante:** {top_var}")
        fig_dist, ax_dist = plt.subplots(figsize=(6, 4), dpi=120)
        sns.histplot(df_students[top_var], kde=True,
                     ax=ax_dist, color="purple")
        ax_dist.set_title(f"Distribui√ß√£o de {top_var}")
        st.pyplot(fig_dist)

    # Chamada do gr√°fico SHAP para o modelo treinado
    plot_shap(modelo, X_train, X_test)


# Avaliar Modelo Selecionado
if botao_avaliar:
    st.write(f"### Avalia√ß√£o do Modelo: **{modelo_selecionado}**")
    treinar_e_avaliar(modelos[modelo_selecionado],
                      X_train, y_train, X_test, y_test)

# Exporta√ß√£o do Modelo
st.subheader("4. Exporta√ß√£o do Modelo para Predi√ß√£o")
st.write("""
Ap√≥s a an√°lise comparativa dos modelos de classifica√ß√£o, o algoritmo Gradient Boosting 
demonstrou performance superior na previs√£o de altera√ß√µes no desempenho escolar. 

Visando a implementa√ß√£o pr√°tica deste conhecimento, procederemos com a exporta√ß√£o do 
modelo treinado em formato pickle, permitindo sua utiliza√ß√£o eficiente na interface 
de predi√ß√£o para novos casos sem a necessidade de retreinamento.
""")
if st.button("Exportar Modelo Gradient Boosting"):
    try:
        # Treinar o modelo com todos os dados dispon√≠veis para m√°xima precis√£o
        modelo_final = GradientBoostingClassifier(
            n_estimators=50, random_state=101)
        modelo_final.fit(X, y)
        os.makedirs("./models", exist_ok=True)
        with open("./models/gradient_boosting_model.pkl", "wb") as f:
            pickle.dump(modelo_final, f)
        with open("./models/label_encoder.pkl", "wb") as f:
            pickle.dump(le, f)
        with open("./models/standard_scaler.pkl", "wb") as f:
            pickle.dump(scaler, f)

        st.success("‚úÖ Modelo Gradient Boosting exportado com sucesso! O algoritmo est√° pronto para realizar predi√ß√µes em tempo real na p√°gina de previs√£o.")
    except Exception as e:
        st.error(f"Erro ao exportar o modelo: {e}")
